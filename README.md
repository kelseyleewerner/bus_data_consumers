Please Note: This repo only contains the consumers for this pipeline. The producers can be found [here](https://github.com/kelseyleewerner/bus_data_producers).

# Guide to Files and Directories in this Repo

**TEST**

Directory contains a sandbox area for testing changes to the consumer before they are introduced to consume_data.py. This also contains a utility for clearing a day's batch of breadcrumb readings from the database to clean up any errors from testing

**bin**

Directory to store the shell scripts for the systemd services that keep the consume_data.py and consume_events.py consumer running continuously

**breadcrumb_data**

Directory to store the text files that were output by the consume_data.py consumer before the Postgres database was implemented

**confluent-env**

Directory to store the Python packages installed to my virtualenv

**log_files**

Directory to store the log files that are output from the consume_data.py and consume_events.py consumers to track data validation warnings and errors

**map_visualizations**

Directory to store the files needed for displaying map speed visualizations, including the raw data queried from Postgres and utilities for formatting data and serving the index.html file that displays the map

**stop_event_data**

Directory to store the text files that were output by the consume_events.py consumer before it was integrated with the Postgres database

**.gitignore**

This file indicates to Git that the following types of files and directories should be ignored:

- Hidden files that have been auto-generated by the system
- The large text files that are stored in breadcrumb_data, log_files, stop_event_data, TEST/test_data, and TEST/log_files

**.vimrc**

Configuration file for vim

**consume_data.py**

This file is a Kafka consumer that receives messages from the breadcrumb_readings Kafka topic, validates and transforms the messages, and then stores them in a Postgres database

**consume_data.service**

This is the systemd service file for the service that keeps the consume_data.py consumer running continuously. In my VM instance this file does not live in my user's home directory (like the rest of the items in this repo) and instead is stored in /etc/systemd/system

**consume_events.py**

This file is a Kafka consumer that receives messages from the stop_events Kafka topic, validates and transforms the messages, and then stores them in a Postgres database

**consume_events.service**

This is the systemd service file for the service that keeps the consume_events.py consumer running continuously. In my VM instance this file does not live in my user's home directory (like the rest of the items in this repo) and instead is stored in /etc/systemd/system
